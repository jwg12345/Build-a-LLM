{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 데이터 준비"
      ],
      "metadata": {
        "id": "WhrDAGbi0XlU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VByvc_jnvFH2",
        "outputId": "0d363300-ee24-43b7-c48f-87103a3fd87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        book_text = file.read()\n",
        "\n",
        "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
        "\n",
        "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
        "\n",
        "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
        "\n",
        "for filename in filenames_list:\n",
        "    clean_text(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 토큰화\n",
        "UTF-8 BPE(Byte Pair Encoding)"
      ],
      "metadata": {
        "id": "cFc1_i531Hum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"Harry Potter was a wizard.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(\"글자수:\", len(text), \"토큰수:\", len(tokens))\n",
        "print(tokens)\n",
        "print(tokenizer.decode(tokens))\n",
        "for t in tokens:\n",
        "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui2wl3dt0-zU",
        "outputId": "b91830fc-eed5-46e5-d808-318f9870a80d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "글자수: 26 토큰수: 6\n",
            "[18308, 14179, 373, 257, 18731, 13]\n",
            "Harry Potter was a wizard.\n",
            "18308\t -> Harry\n",
            "14179\t ->  Potter\n",
            "373\t ->  was\n",
            "257\t ->  a\n",
            "18731\t ->  wizard\n",
            "13\t -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer # pip install transformers\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
        "\n",
        "# print(\"Vocab size :\", len(tokenizer))\n",
        "\n",
        "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
        "\n",
        "# tokens = tokenizer.encode(text)\n",
        "\n",
        "# print(len(text), len(tokens))\n",
        "# print(tokens)\n",
        "# print(tokenizer.decode(tokens))"
      ],
      "metadata": {
        "id": "oLGbou8k0-w2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for char in text:\n",
        "    token_ids = tokenizer.encode(char)\n",
        "    decoded = tokenizer.decode(token_ids)\n",
        "    print(f\"{char} -> {token_ids} -> {decoded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V-AE5_n0-uI",
        "outputId": "8f490f9a-d853-4ca8-875a-8537ba96491d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H -> [39] -> H\n",
            "a -> [64] -> a\n",
            "r -> [81] -> r\n",
            "r -> [81] -> r\n",
            "y -> [88] -> y\n",
            "  -> [220] ->  \n",
            "P -> [47] -> P\n",
            "o -> [78] -> o\n",
            "t -> [83] -> t\n",
            "t -> [83] -> t\n",
            "e -> [68] -> e\n",
            "r -> [81] -> r\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "a -> [64] -> a\n",
            "s -> [82] -> s\n",
            "  -> [220] ->  \n",
            "a -> [64] -> a\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "i -> [72] -> i\n",
            "z -> [89] -> z\n",
            "a -> [64] -> a\n",
            "r -> [81] -> r\n",
            "d -> [67] -> d\n",
            ". -> [13] -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터로더(DataLoader)"
      ],
      "metadata": {
        "id": "rTqNWw0N4IIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, txt, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        print(\"# of tokens in txt:\", len(token_ids))\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "    txt = file.read()\n",
        "\n",
        "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqoLRsd00-rv",
        "outputId": "b56c182e-7c25-4b89-ca49-d8fe8b504e22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of tokens in txt: 130520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "\n",
        "x, y = next(dataiter) # x, y <- self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "print(tokenizer.decode(x[0].tolist()))\n",
        "print(tokenizer.decode(y[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAp562Fr0-mf",
        "outputId": "38f3aee1-e035-4d11-f251-a47d40231595"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " exactly like the sort of thing Malfoy would do. Had Harry been stupid to take Dobby seriously? “I’m glad we came to get you\n",
            " like the sort of thing Malfoy would do. Had Harry been stupid to take Dobby seriously? “I’m glad we came to get you,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 뉴럴네트워크 모델 정의"
      ],
      "metadata": {
        "id": "-Jp1gXaK7onl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 정의할 때 사용하는 상수들\n",
        "\n",
        "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
        "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
        "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
        "EMB_DIM = 768  # Embedding dimension\n",
        "NUM_HEADS = 12  # Number of attention heads\n",
        "NUM_LAYERS = 12  # Number of layers\n",
        "DROP_RATE = 0.1  # Dropout rate\n",
        "QKV_BIAS = False  # Query-key-value bias"
      ],
      "metadata": {
        "id": "zyVpGPEf0-kN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.head_dim = d_out // NUM_HEADS\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(DROP_RATE)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=EMB_DIM,\n",
        "            d_out=EMB_DIM)\n",
        "\n",
        "        self.ff = FeedForward()\n",
        "        self.norm1 = LayerNorm(EMB_DIM)\n",
        "        self.norm2 = LayerNorm(EMB_DIM)\n",
        "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
        "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
        "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
        "\n",
        "        self.final_norm = LayerNorm(EMB_DIM)\n",
        "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "MVVGnuq87ceR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련"
      ],
      "metadata": {
        "id": "cSKduvrb_hrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zGIauA7cbg",
        "outputId": "3cdbdb2a-bfc6-45fa-d55d-091d1ff3e9b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tokens_seen, global_step = 0, -1\n",
        "losses = []\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/20\")\n",
        "\n",
        "    for input_batch, target_batch in pbar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_batch = input_batch.to(device)\n",
        "        target_batch = target_batch.to(device)\n",
        "\n",
        "        logits = model(input_batch)\n",
        "\n",
        "        loss = torch.nn.functional.cross_entropy(\n",
        "            logits.flatten(0, 1),\n",
        "            target_batch.flatten()\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        tokens_seen += input_batch.numel()\n",
        "        global_step += 1\n",
        "\n",
        "        # tqdm 우측에 실시간 정보 표시\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{loss.item():.4f}\",\n",
        "            \"tokens\": tokens_seen\n",
        "        })\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} finished | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    torch.save(\n",
        "        model.state_dict(),\n",
        "        f\"model_{str(epoch + 1).zfill(3)}.pth\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE0MIhFfCDEc",
        "outputId": "7528bdc9-c412-49f2-924f-84ba78f4bf01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.7689, tokens=1040384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 finished | Avg Loss: 1.3094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.4306, tokens=2080768]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 finished | Avg Loss: 0.4942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 254/254 [04:38<00:00,  1.09s/it, loss=0.3340, tokens=3121152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 finished | Avg Loss: 0.3318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 254/254 [04:38<00:00,  1.10s/it, loss=0.2931, tokens=4161536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 finished | Avg Loss: 0.2824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 254/254 [04:38<00:00,  1.09s/it, loss=0.2844, tokens=5.2e+6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 finished | Avg Loss: 0.2598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2590, tokens=6242304]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 finished | Avg Loss: 0.2473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2580, tokens=7282688]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 finished | Avg Loss: 0.2390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2714, tokens=8323072]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 finished | Avg Loss: 0.2334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2367, tokens=9363456]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 finished | Avg Loss: 0.2283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2460, tokens=1.04e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 finished | Avg Loss: 0.2229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2251, tokens=1.14e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 finished | Avg Loss: 0.2188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2115, tokens=1.25e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 finished | Avg Loss: 0.2155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2247, tokens=1.35e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 finished | Avg Loss: 0.2137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 254/254 [04:38<00:00,  1.09s/it, loss=0.2211, tokens=1.46e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 finished | Avg Loss: 0.2106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 254/254 [04:38<00:00,  1.09s/it, loss=0.2194, tokens=1.56e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 finished | Avg Loss: 0.2080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2420, tokens=1.66e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 finished | Avg Loss: 0.2059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2150, tokens=1.77e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17 finished | Avg Loss: 0.2043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2116, tokens=1.87e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18 finished | Avg Loss: 0.2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2063, tokens=1.98e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19 finished | Avg Loss: 0.2003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 254/254 [04:37<00:00,  1.09s/it, loss=0.2130, tokens=2.08e+7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20 finished | Avg Loss: 0.1994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1_0QZ_ek7cVE",
        "outputId": "bd30f28f-8f8e-4ad6-9943-bd71297e2baa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 확인"
      ],
      "metadata": {
        "id": "YRTFB6kyANSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
        "model.load_state_dict(torch.load(\"model_020.pth\", map_location=device, weights_only=True))\n",
        "model.eval() # dropout을 사용하지 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNXoXr3p7cSb",
        "outputId": "c540efd7-6671-4ed8-d88f-1b6f58250a5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(128, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
        "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(idx)\n",
        "\n",
        "logits = logits[:, -1, :]\n",
        "\n",
        "# 가장 확률이 높은 단어 10개 출력\n",
        "top_logits, top_indices = torch.topk(logits, 10)\n",
        "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
        "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
        "\n",
        "# 가장 확률이 높은 단어 출력\n",
        "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
        "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIxZvNEB7cQE",
        "outputId": "aecc12f5-e47f-4747-ec21-8789300563e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.09\t 257\t  a\n",
            "11.29\t 973\t  used\n",
            "10.17\t 4978\t  caught\n",
            "8.76\t 635\t  also\n",
            "8.53\t 30\t ?\n",
            "8.51\t 1464\t  always\n",
            "8.01\t 655\t  just\n",
            "7.88\t 13\t .\n",
            "7.85\t 262\t  the\n",
            "7.80\t 1479\t  free\n",
            " a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "wWAB_Ghm7cMx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = input(\"Start context: \")\n",
        "\n",
        "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
        "idx = tokenizer.encode(start_context)\n",
        "idx = torch.tensor(idx).unsqueeze(0)\n",
        "\n",
        "context_size = model.pos_emb.weight.shape[0]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=idx.to(device),\n",
        "        max_new_tokens=10,\n",
        "        context_size= context_size,\n",
        "        top_k=10,\n",
        "        temperature=100\n",
        "    )\n",
        "\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
        "\n",
        "    print(i, \":\", out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3PRxf220-hn",
        "outputId": "46712810-2e50-4a5c-af7a-fa86221ec98e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start context: Dobby is\n",
            "0 : Dobby is also warning the culprit door — died quite suddenly became\n",
            "1 : Dobby is free without Mum got his own powers rival are named\n",
            "2 : Dobby is a dark stone tunnel at Hogwarts? Someone opened the\n",
            "3 : Dobby is also! Broantly all records! SIL son must\n",
            "4 : Dobby is also stowed. So. I tell Crab Lord\n",
            "5 : Dobby is always a diversion in front seats as the dish shattered\n",
            "6 : Dobby is? � coming toward me, Harry Potter — �\n",
            "7 : Dobby is also all these attacks,� history is to start\n",
            "8 : Dobby is also st times to death here, Weasley? Plenty\n",
            "9 : Dobby is the monster it. He. Very fortunate someone be\n"
          ]
        }
      ]
    }
  ]
}